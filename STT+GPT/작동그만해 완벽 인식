from google.cloud import speech_v1p1beta1 as speech
import os
import pyaudio
import time
import threading
import openai
import configparser
import numpy as np

# Google Cloud STT API 키 인증
os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = "C:\\Users\\wwsgb\\Json_key\\stt_json_key\\buoyant-mason-412215-845850c6db6c.json"

# 설정파일 로드
config = configparser.ConfigParser()
config.read('config.ini')
openai.api_key = config.get('api_keys', 'openai_key')

# OpenAI GPT 응답을 받는 함수
def get_gpt_response(text):
    try:
        response = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",  # 챗 모델 선택
            messages=[
                {"role": "user", "content": text}
            ]
        )
        return response.choices[0].message["content"].strip()
    except Exception as e:
        return f"An error occurred: {str(e)}"

class Transcriber:
    def __init__(self):
        self.client = speech.SpeechClient()
        self.transcript = ""             #변환 텍스트 저장 및 마지막 변환시간 저장할 변수 
        self.last_transcript_time = time.time() 
        self.silence_threshold = 0.3     #정지 감지할 시간 임계값 
        self.running = True

    def transcribe_streaming(self):
        while self.running:
            config = speech.RecognitionConfig(
                encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,
                sample_rate_hertz=16000,
                language_code="ko-KR",
            )
            streaming_config = speech.StreamingRecognitionConfig(
                config=config, interim_results=True
            )
            p = pyaudio.PyAudio()
            stream = p.open(
                format=pyaudio.paInt16, channels=1, rate=16000, input=True, frames_per_buffer=1024
            )

            def generate_requests():
                while True:
                    data = stream.read(1024)
                    if not data:
                        break
                    yield speech.StreamingRecognizeRequest(audio_content=data)

            requests = generate_requests()
            responses = self.client.streaming_recognize(streaming_config, requests)
            for response in responses:
                if not response.results:
                    continue
                result = response.results[-1]
                if result.is_final:
                    self.transcript = result.alternatives[0].transcript
                    self.last_transcript_time = time.time()
                else:
                    transcript = result.alternatives[0].transcript
                    if "작동 그만해" in transcript:
                        self.running = False
                        print("프로그램 중단")
                        stream.stop_stream()
                        stream.close()
                        p.terminate()
                        break

            stream.stop_stream()
            stream.close()
            p.terminate()
                    
    # 임계값 도달 -> 텍스트 변환 작업 수행
    def monitor_silence(self):
        while self.running:
            if time.time() - self.last_transcript_time > self.silence_threshold:
                if self.transcript:
                    print("변환 텍스트: {}".format(self.transcript))
                    gpt_response = get_gpt_response(self.transcript)
                    print("GPT 응답: {}".format(gpt_response))

                    #텍스트 초기화 및 마지막 텍스트 시간 입력
                    self.transcript = ""
                    self.last_transcript_time = time.time()

                # 0.3초 기다렸다가 임계값 다시 확인
                time.sleep(0.3)

transcriber = Transcriber()
transcription_thread = threading.Thread(target=transcriber.transcribe_streaming)
monitor_thread = threading.Thread(target=transcriber.monitor_silence)

#스레드 시작
transcription_thread.start()
monitor_thread.start()

# 스레드 종료까지 대기
transcription_thread.join()
monitor_thread.join()
